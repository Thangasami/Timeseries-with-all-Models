{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from sklearn import linear_model\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.tsa.holtwinters import SimpleExpSmoothing\n",
    "from fbprophet import Prophet\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"Data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\sthan\\\\Python\\\\Machine Learning\\\\Time Series'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd = os.getcwd()\n",
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Volume'] = data['Decomposition_1']\n",
    "del data['Decomposition_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regression model\n",
    "def Regression(data):\n",
    "    data[\"Date\"] = pd.to_datetime(data[\"Date\"])\n",
    "    data=data.sort_values([\"Date\"])\n",
    "    data[\"Quarter\"] = data[\"Date\"].dt.quarter\n",
    "    data[\"Year\"] = data[\"Date\"].dt.year\n",
    "    data[\"Month\"] = data[\"Date\"].dt.month\n",
    "    \n",
    "    Train=data[(data.Year>=2017)&(data.Year<2019)] #modify date according to your dataset; Train : 2017-2018\n",
    "    Test=data[(data.Year==2019)]  #modify date according to your dataset; Test : 2019\n",
    "    \n",
    "    \n",
    "    Train[\"SI_Y\"]=Train[\"Volume\"]/Train.groupby(\"Year\")[\"Volume\"].transform(np.mean)\n",
    "    Train[\"F_SI\"]=Train.groupby(\"Month\")[\"SI_Y\"].transform(np.mean)\n",
    "    Train[\"D_Seasonalised_trend\"] = Train[\"Volume\"]/Train[\"F_SI\"]    \n",
    "    Train[\"Level_index1\"]=np.mean(Train[(Train.Year==2018)&(Train.Quarter==1)][\"D_Seasonalised_trend\"])/np.mean(Train[(Train.Year==2017)&(Train.Quarter==4)][\"D_Seasonalised_trend\"])\n",
    "    \n",
    "    numer1=np.mean(Train[(Train.Year==2018)&(Train.Quarter==3)][\"D_Seasonalised_trend\"])/np.mean(Train[(Train.Year==2018)&(Train.Quarter==2)][\"D_Seasonalised_trend\"])\n",
    "    numer2=np.mean(Train[(Train.Year==2018)&(Train.Quarter==4)][\"D_Seasonalised_trend\"])/np.mean(Train[(Train.Year==2018)&(Train.Quarter==3)][\"D_Seasonalised_trend\"])\n",
    "    \n",
    "    \n",
    "    Train[\"Level_index2\"]=np.mean([numer1,numer2])\n",
    "    Train=Train.sort_values([\"Date\"])\n",
    "    Train.index=range(len(Train))\n",
    "    Train[\"ID\"]=range(1,(len(Train)+1))\n",
    "    \n",
    "    Train[\"Deleveled_series\"]=np.where(Train.Year==2017, Train[\"D_Seasonalised_trend\"]*Train[\"Level_index1\"],Train[\"D_Seasonalised_trend\"])\n",
    "    \n",
    "    lm = linear_model.LinearRegression()\n",
    "    X = np.array(Train[[\"ID\", \"Variable_1\"]]) # In case of no extra variable in the dataset, remove the extra variable name from the list, then append the line with \".reshape(-1, 1)\"\n",
    "    Y = np.array(Train[\"Deleveled_series\"]).reshape(-1,1)\n",
    "    \n",
    "    model = lm.fit(X,Y)\n",
    "    \n",
    "    Test[\"ID\"]=range(len(Test))\n",
    "    Test[\"ID\"]=Test[\"ID\"]+max(Train[\"ID\"])\n",
    "    X_test=np.array(Test[[\"ID\", \"Variable_1\"]]) # In case of no extra variable in the dataset, remove the extra variable name from the list, then append the line with \".reshape(-1, 1)\"\n",
    "    Y_test=model.predict(X_test)\n",
    "    \n",
    "    Pred1 = Y_test*Train.iloc[0][\"Level_index2\"]*np.array(Train.iloc[0:len(Y_test)][\"F_SI\"]).reshape(-1,1)\n",
    "    Test[\"Predictions\"]=Pred1\n",
    "    \n",
    "    return(Test['Predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Arima(data): \n",
    "    X = data['Volume'].values\n",
    "    size = np.sum(data['Date']<='12/31/2018')\n",
    "    train, test = X[0:size], X[size:len(X)]\n",
    "    history = [x for x in train]\n",
    "    predictions = list()  \n",
    "        \n",
    "    for t in range(len(test)):\n",
    "    \tmodel = ARIMA(history, order=(1,1,0))\n",
    "    \tmodel_fit = model.fit(disp=0)\n",
    "    \toutput = model_fit.forecast()\n",
    "    \tyhat = output[0]\n",
    "    \tpredictions.append(yhat)\n",
    "    \tobs = test[t]\n",
    "    \thistory.append(obs)\n",
    "    return predictions   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Holts_winter(data):\n",
    "    inter_df = data[['Volume']]\n",
    "    size = np.sum(data['Date']<='12/31/2018')\n",
    "    train, test = inter_df.iloc[:size, 0], inter_df.iloc[size:, 0]\n",
    "    model = ExponentialSmoothing(train, seasonal='mul', seasonal_periods=12).fit()\n",
    "    pred = model.predict(start=test.index[0], end=test.index[-1])\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fbprophet\n",
    "def Fbprophet(data):\n",
    "    size = np.sum(data['ds']<='12/31/2018')\n",
    "    inter_df = data.iloc[:size, :]\n",
    "    m = Prophet(weekly_seasonality=False, daily_seasonality=False, yearly_seasonality=True)\n",
    "    m.fit(inter_df)\n",
    "    future = m.make_future_dataframe(periods=12, freq='M')\n",
    "    forecast = m.predict(future)\n",
    "    fcst = forecast['yhat'].tail(12)\n",
    "    return fcst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple Exponential Smoothing model\n",
    "def Ses(data):\n",
    "    inter_df = data[['Volume']]\n",
    "    size = np.sum(data['Date']<='12/31/2018')\n",
    "    train, test = inter_df.iloc[:size, 0], inter_df.iloc[size:, 0]\n",
    "    model = SimpleExpSmoothing(train).fit()\n",
    "    pred = model.predict(start=test.index[0], end=test.index[-1])\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Regression_2lag(data):\n",
    "    data[\"Variable_1\"] = data[\"Variable_1\"].shift(2)\n",
    "    data = data.loc[2:, :]\n",
    "    return Regression(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "required_cols = [col for col in data.columns if col not in ['Date', 'Variable_1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Volume']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "required_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Result=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for model in [Regression]:\n",
    "for model in [Regression, Arima, Holts_winter, Ses, Regression_2lag]:\n",
    "    for i in required_cols:\n",
    "        data['Date'] = pd.to_datetime(data['Date'])\n",
    "        to_func = data[[\"Date\", \"Variable_1\", i]]\n",
    "        to_func.columns=[\"Date\",\"Variable_1\", \"Volume\"]\n",
    "        if model == Fbprophet:\n",
    "            to_func.columns=[\"ds\",\"Variable_1\", \"y\"]\n",
    "            Result_inter = model(to_func[['ds', 'y']])\n",
    "            Result_inter.name = model.__name__ + \"_\" +  i\n",
    "            Result_inter.index = range(len(Result_inter))\n",
    "            Result = pd.concat([Result, Result_inter], axis = 1)\n",
    "        elif model == Arima:\n",
    "            Result_inter = model(to_func)\n",
    "            Result_inter = pd.DataFrame(Result_inter, columns = [\"ARIMA_\" + i])\n",
    "            Result_inter.index=range(len(Result_inter))\n",
    "            Result = pd.concat([Result, Result_inter], axis = 1)\n",
    "        else:\n",
    "            Result_inter = model(to_func)\n",
    "            Result_inter.name = model.__name__ + \"_\" +  i\n",
    "            Result_inter.index=range(len(Result_inter))\n",
    "            Result = pd.concat([Result, Result_inter], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in [Regression, Arima, Holts_winter, Ses, Fbprophet, Regression_2lag]:\n",
    "    for i in required_cols:\n",
    "        data['Date'] = pd.to_datetime(data['Date'])\n",
    "        to_func = data[[\"Date\", \"Variable_1\", i]]\n",
    "        to_func.columns=[\"Date\",\"Variable_1\", \"Volume\"]\n",
    "        if model == Fbprophet:\n",
    "            to_func.columns=[\"ds\",\"Variable_1\", \"y\"]\n",
    "            Result_inter = model(to_func[['ds', 'y']])\n",
    "            Result_inter.name = model.__name__ + \"_\" +  i\n",
    "            Result_inter.index = range(len(Result_inter))\n",
    "            Result = pd.concat([Result, Result_inter], axis = 1)\n",
    "        elif model == Arima:\n",
    "            Result_inter = model(to_func)\n",
    "            Result_inter = pd.DataFrame(Result_inter, columns = [\"ARIMA_\" + i])\n",
    "            Result_inter.index=range(len(Result_inter))\n",
    "            Result = pd.concat([Result, Result_inter], axis = 1)\n",
    "        else:\n",
    "            Result_inter = model(to_func)\n",
    "            Result_inter.name = model.__name__ + \"_\" +  i\n",
    "            Result_inter.index=range(len(Result_inter))\n",
    "            Result = pd.concat([Result, Result_inter], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Regression_Volume</th>\n",
       "      <th>ARIMA_Volume</th>\n",
       "      <th>Holts_winter_Volume</th>\n",
       "      <th>Ses_Volume</th>\n",
       "      <th>Regression_2lag_Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201164.591622</td>\n",
       "      <td>267231.137280</td>\n",
       "      <td>207931.196738</td>\n",
       "      <td>259756.0</td>\n",
       "      <td>185443.882798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>190553.630456</td>\n",
       "      <td>282154.150945</td>\n",
       "      <td>194435.815959</td>\n",
       "      <td>259756.0</td>\n",
       "      <td>195071.209180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>188298.718889</td>\n",
       "      <td>302615.513024</td>\n",
       "      <td>190649.510261</td>\n",
       "      <td>259756.0</td>\n",
       "      <td>205680.776848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>196359.687508</td>\n",
       "      <td>322403.289411</td>\n",
       "      <td>197737.865156</td>\n",
       "      <td>259756.0</td>\n",
       "      <td>205566.155440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>207455.232896</td>\n",
       "      <td>341869.820756</td>\n",
       "      <td>207719.008639</td>\n",
       "      <td>259756.0</td>\n",
       "      <td>191485.135052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Regression_Volume   ARIMA_Volume  Holts_winter_Volume  Ses_Volume  \\\n",
       "0      201164.591622  267231.137280        207931.196738    259756.0   \n",
       "1      190553.630456  282154.150945        194435.815959    259756.0   \n",
       "2      188298.718889  302615.513024        190649.510261    259756.0   \n",
       "3      196359.687508  322403.289411        197737.865156    259756.0   \n",
       "4      207455.232896  341869.820756        207719.008639    259756.0   \n",
       "\n",
       "   Regression_2lag_Volume  \n",
       "0           185443.882798  \n",
       "1           195071.209180  \n",
       "2           205680.776848  \n",
       "3           205566.155440  \n",
       "4           191485.135052  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
